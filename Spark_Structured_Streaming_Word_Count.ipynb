{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b7f4ab5-0126-42f5-ba65-42f21f9b34b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark real-time streaming exercise\n",
    "# July 26, 2025\n",
    "# Ref: https://spark.apache.org/docs/latest/streaming/getting-started.html\n",
    "# Use virenv since latest Java, Spark, PySpark, and Python are not compatible \n",
    "# pyenv install 3.11.9\n",
    "# pyenv virtualenv 3.11.9 pyspark311\n",
    "# Remember to run the Jupyter Notebook within the virtualenv\n",
    "# export JAVA_HOME=\"/opt/homebrew/opt/openjdk@11\"\n",
    "# export PATH=\"$JAVA_HOME/bin:$PATH\"\n",
    "# pip install pyspark jupyterlab findspark\n",
    "# pyenv activate pyspark311\n",
    "# jupyter lab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17c9b90-1619-4416-8c66-c259ed70e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verified Java is installed properly\n",
    "import os\n",
    "print(os.environ.get(\"JAVA_HOME\"))\n",
    "\n",
    "# Should see something like this:/Users/miaolin/Library/Caches/Coursier/arc/https/github.com/adoptium/temurin11-binaries/releases/download/jdk-11.0.27%252B6/OpenJDK11U-jdk_aarch64_mac_hotspot_11.0.27_6.tar.gz/jdk-11.0.27+6/Contents/Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5309d53b-64be-4cae-b89b-62c5c59fdee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nano ~/.zshrc\n",
    "# Add the path to the end of the file\n",
    "# source ~/.zshrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fcf0ab5-1766-4203-a6f7-c74c91acb871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix var path\n",
    "import os\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/opt/homebrew/opt/openjdk@11\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/Users/miaolin/Downloads/spark-3.5.6-bin-hadoop3\"\n",
    "os.environ[\"PATH\"] = os.environ[\"SPARK_HOME\"] + \"/bin:\" + os.environ.get(\"PATH\", \"\")\n",
    "\n",
    "findspark.init(os.environ[\"SPARK_HOME\"])\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Test\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "print(\"Spark session created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86854245-8ddf-4ea0-abfe-2b8fc87bbcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAVA_HOME = /opt/homebrew/opt/openjdk@11\n",
      "SPARK_HOME = /Users/miaolin/Downloads/spark-3.5.6-bin-hadoop3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"JAVA_HOME =\", os.environ.get(\"JAVA_HOME\"))\n",
    "print(\"SPARK_HOME =\", os.environ.get(\"SPARK_HOME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9d4b0fd-e963-4a76-9316-6b40a6a25ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pyspark\n",
      "Version: 4.0.0\n",
      "Summary: Apache Spark Python API\n",
      "Home-page: https://github.com/apache/spark/tree/master/python\n",
      "Author: Spark Developers\n",
      "Author-email: dev@spark.apache.org\n",
      "License: http://www.apache.org/licenses/LICENSE-2.0\n",
      "Location: /Users/miaolin/.pyenv/versions/3.11.9/envs/pyspark311/lib/python3.11/site-packages\n",
      "Requires: py4j\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Verified PySpark installation\n",
    "# pip show pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9aab0c4-c423-417d-9002-c5e9d26586a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"StructuredNetworkWordCount\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a0bd3-9a5c-4533-9e5b-e4d09c86e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nc -lk 9999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c8f5d5-fee3-4221-9435-cdd84616798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame representing the stream of input lines from connection to localhost:9999\n",
    "lines = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"socket\") \\\n",
    "    .option(\"host\", \"localhost\") \\\n",
    "    .option(\"port\", 9999) \\\n",
    "    .load()\n",
    "\n",
    "# Split the lines into words\n",
    "words = lines.select(\n",
    "   explode(\n",
    "       split(lines.value, \" \")\n",
    "   ).alias(\"word\")\n",
    ")\n",
    "\n",
    "# Generate running word count\n",
    "wordCounts = words.groupBy(\"word\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7590a0a-02a7-4fb4-9308-00bd7fdc5874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/26 13:03:39 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    " # Start running the query that prints the running counts to the console\n",
    "query = wordCounts \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c33e65d-472b-495e-8a9f-6dbfc316ca39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
